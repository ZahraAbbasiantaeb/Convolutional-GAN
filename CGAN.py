# -*- coding: utf-8 -*-
"""GAN_Kg.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Bt9oQhEduHBfz3wHYMGjBjJWfyJmuSsJ
"""

!pip install kaggle
# %cd /root
!mkdir .kaggle
import json
token = {"username":"masafa","key":"4c96b626a191c2c6aa61e9fdffe4a7b6"}
with open('/root/.kaggle/kaggle.json', 'w') as file:
    json.dump(token, file)

!kaggle config set -n path -v/content

# %cd /content

!chmod 600 /root/.kaggle/kaggle.json

!kaggle datasets download kostastokis/simpsons-faces  -p ./

!unzip simpsons-faces.zip -d faces

!unzip faces/cropped.zip -d data/

rm -r simpsons-faces.zip

!rm -rf 'data/__MACOSX'

import numpy as np
from PIL import Image

def convert_image_to_array():

    images = []

    for i in range(1,9878):
        filename = 'data/'+str(i)
        img = Image.open(filename + '.png' )
        data = np.array(img, dtype='uint8' )
        images.append(data/255)


    return images

main_images = convert_image_to_array()

images = np.array(main_images) 
images = images.astype('float32')[0:1000]

import numpy as np
import pandas as pd 
import keras
from keras.layers import Input, Dense, Reshape, Flatten, Dropout
from keras.layers import BatchNormalization, Activation, ZeroPadding2D
from keras.layers.advanced_activations import LeakyReLU
from keras.layers.convolutional import UpSampling2D, Conv2D
from keras.models import Sequential, Model
from keras.optimizers import Adam
from PIL import Image
import matplotlib.pyplot as plt
import seaborn as sns
import glob
import os

img_rows = 200
img_cols = 200
channels = 3
img_shape = (img_rows, img_cols, channels)

optimizer = Adam(0.0002, 0.5)

def create_generator():

  generator = Sequential()

  generator.add(Dense(128 * 50 * 50, activation="relu", input_dim=100))
  generator.add(Reshape((50, 50, 128)))
  generator.add(UpSampling2D())


  generator.add(Conv2D(128, kernel_size=3, padding="same"))
  generator.add(BatchNormalization(momentum=0.8))
  generator.add(Activation("relu"))

  generator.add(UpSampling2D())

  generator.add(Conv2D(channels, kernel_size=7, padding="same"))
  generator.add(Activation("tanh"))

  generator.summary()
  
  return generator

def create_discriminator():

    discriminator = Sequential()

    discriminator.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding="same"))
    discriminator.add(LeakyReLU(alpha=0.2))
    discriminator.add(Dropout(0.25))

    discriminator.add(Conv2D(64, kernel_size=5, strides=2, padding="same"))
    discriminator.add(ZeroPadding2D(padding=((0,1),(0,1))))
    discriminator.add(BatchNormalization(momentum=0.8))
    discriminator.add(LeakyReLU(alpha=0.2))
    discriminator.add(Dropout(0.25))


    discriminator.add(Conv2D(128, kernel_size=4, strides=2, padding="same"))
    discriminator.add(BatchNormalization(momentum=0.8))
    discriminator.add(LeakyReLU(alpha=0.2))
    discriminator.add(Dropout(0.25))


    discriminator.add(Conv2D(256, kernel_size=3, strides=1, padding="same"))
    discriminator.add(BatchNormalization(momentum=0.8))
    discriminator.add(LeakyReLU(alpha=0.2))
    discriminator.add(Dropout(0.25))
    discriminator.add(Flatten())
    discriminator.add(Dense(1, activation='sigmoid'))

    discriminator.summary()
    discriminator.compile(loss='binary_crossentropy',
                optimizer=optimizer,
                metrics=['accuracy'])

    return discriminator

fig_space_size = 8

import matplotlib.gridspec as gridspec

def plot_generated_images(generated_images):

    plt.figure(figsize=(fig_space_size, fig_space_size), num=2)
    gs1 = gridspec.GridSpec(fig_space_size, fig_space_size)
    gs1.update(wspace=0, hspace=0)

    for i in range(batch_size):
      
        ax = plt.subplot(gs1[i])
        ax.set_aspect('equal')
        image = generated_images[i, :, :, :]
        image *= 255
        fig = plt.imshow(image.astype(np.uint8))
        
        plt.axis('off')
        
        fig.axes.get_xaxis().set_visible(False)
        fig.axes.get_yaxis().set_visible(False)

    plt.tight_layout()
    
    save_name = 'generatedSamples_'+str(i)+'.png'

    plt.savefig(save_name, bbox_inches='tight', pad_inches=0)
    plt.pause(0.000000001)
    plt.show()

discriminator = create_discriminator()

generator = create_generator()

z = Input(shape=(100,))

img = generator(z)

discriminator.trainable = False

valid = discriminator(img)

combined = Model(z, valid)

combined.compile(loss='binary_crossentropy', optimizer=optimizer)

batch_size = 64

valid = np.ones((batch_size, 1))
fake = np.zeros((batch_size, 1))



disc_loss = []
gen_loss = []
disc_acc = []

batch_count = int(images.shape[0]/batch_size)

for epoch in range(0, 50):

  for i in range(0, batch_count):
    
    imgs = images[i*batch_size: (i+1)*batch_size]
# + np.random.uniform(0, 1, size=(batch_size, 200,200,3))*0.2
    

    noise = np.random.normal(0, 1, (batch_size, 100))
    gen_imgs = generator.predict(noise)

    d_loss_real = discriminator.train_on_batch(imgs, valid)
    d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)
    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

    g_loss = combined.train_on_batch(noise, valid)
    
    disc_loss.append(d_loss[0])
    gen_loss.append(g_loss)
    disc_acc.append(d_loss[1])
    
    
  print ("%d D loss: %f, acc.: %.2f%% ,  G loss: %f" % (epoch, d_loss[0], 100*d_loss[1], g_loss))

  generator.save("generator.model")
  
  discriminator.save("discriminator.model")
  
        
  gen_imgs = generator.predict(noise)

  plot_generated_images(gen_imgs)

  plt.plot(disc_loss, label='Discriminator Loss')
        
  plt.plot(gen_loss, label='Generator Loss')

  plt.legend(loc='upper left')
        
  plt.show()
        
  plt.plot(disc_acc, label='disc accuracy')

  plt.legend(loc='upper left')
        
  plt.show()
        
  plt.close()

from keras.models import load_model

discriminator = load_model('discriminator.model')
generator = load_model('generator.model')

from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix


test_size = 100

noise = np.random.normal(0, 1, (test_size, 100))

y = np.zeros( 2 * test_size) 

test_images = np.zeros((2* test_size, img_rows, img_cols,3))
test_images[0:test_size] = generator.predict(noise)


test_images[test_size:2*test_size] = images[0:test_size]
  
y[test_size:2*test_size] = 1



disc_loss, disc_acc = discriminator.evaluate(test_images, y )

print(disc_loss, disc_acc )
y_pred = discriminator.predict(test_images )

y_pred = list(y_pred)

for i in range(0, len(y_pred)):
  if(y_pred[i]<0.5):
    y_pred[i] = 0
  else:
    y_pred[i] = 1
    
print(classification_report(y, y_pred))

print(confusion_matrix(y, y_pred))

from google.colab import drive
drive.mount('/content/drive')

generator.save("drive/My Drive/NeuralNetwork_Models/generator_conv2.model")
  discriminator.save("drive/My Drive/NeuralNetwork_Models/discriminator_conv2.model")